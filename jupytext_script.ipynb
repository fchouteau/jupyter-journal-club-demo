{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import SVG\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.VERSION)\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = len(y_train)\n",
    "num_test_examples = len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config\n",
    "Configuration required for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training configuration\n",
    "MAX_LR = 0.1\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "NUM_TRAIN_STEPS = int(num_train_examples / BATCH_SIZE)\n",
    "NUM_TEST_STEPS = int(num_test_examples / BATCH_SIZE)\n",
    "FILTERS = [16, 32, 64, 64]\n",
    "OPTIMIZER = tf.keras.optimizers.SGD(lr=MAX_LR, momentum=0.9, nesterov=True)\n",
    "LOSS = tf.keras.losses.categorical_crossentropy\n",
    "METRICS = [\n",
    "    tf.keras.metrics.categorical_accuracy,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functions\n",
    "def preprocess_example(img, label):\n",
    "    img = tf.expand_dims(img, axis=-1)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img /= 255.\n",
    "\n",
    "    label = tf.one_hot(label, depth=10)\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dataset_fn():\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=10000).repeat() \\\n",
    "        .map(preprocess_example) \\\n",
    "        .batch(64) \\\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset_fn():\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    test_dataset = test_dataset.repeat().map(preprocess_example).batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get keras model\n",
    "def mini_cnn(input_shape,\n",
    "             num_classes,\n",
    "             filters=[16, 32, 64, 64],\n",
    "             activation=\"softmax\",\n",
    "             model_name=\"basic_cnn4\",\n",
    "             **conv_kwargs):\n",
    "    use_bias = False\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters[0], (3, 3), padding=\"same\", use_bias=use_bias, **conv_kwargs)(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=2)(x)\n",
    "    x = tf.keras.layers.Conv2D(filters[1], (3, 3), padding=\"same\", use_bias=use_bias, **conv_kwargs)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=2)(x)\n",
    "    x = tf.keras.layers.Conv2D(filters[2], (3, 3), padding=\"same\", use_bias=use_bias, **conv_kwargs)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), strides=2)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(filters[3], use_bias=use_bias, **conv_kwargs)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "    logits = tf.keras.layers.Dense(\n",
    "        num_classes, use_bias=True, name=\"logits\", bias_initializer=tf.keras.initializers.constant(0.1))(x)\n",
    "    probas = tf.keras.layers.Activation(activation=activation, name=\"probas\")(logits)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=probas, name=model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_scheduler(epoch, warmup=10):\n",
    "    _epoch = epoch + 1\n",
    "    if _epoch < 10:\n",
    "        return MAX_LR * float(_epoch / warmup)\n",
    "    else:\n",
    "        c = (_epoch - warmup) / (NUM_EPOCHS - warmup)\n",
    "\n",
    "        return MAX_LR * (1. / 2.) * (1. + np.cos(np.pi * c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model\n",
    "keras_model = mini_cnn(\n",
    "    input_shape=(28, 28, 1),\n",
    "    num_classes=10,\n",
    "    filters=FILTERS,\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "    model_name=\"fashion_mnist_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALLBACKS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get visualisation\n",
    "SVG(model_to_dot(keras_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "keras_model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit\n",
    "history = keras_model.fit(\n",
    "    train_dataset_fn(),\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=2,\n",
    "    callbacks=CALLBACKS,\n",
    "    validation_data=test_dataset_fn(),\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=NUM_TRAIN_STEPS,\n",
    "    validation_steps=NUM_TEST_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "x_test_ = np.expand_dims(x_test, axis=-1) / 255.\n",
    "y_true = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "y_pred = keras_model.predict(x_test_, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pr curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(10):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_true[:, i], y_pred[:, i])\n",
    "    average_precision[i] = average_precision_score(y_true[:, i], y_pred[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A \"micro-average\": quantifying score on all classes jointly\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_true.ravel(), y_pred.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_true, y_pred, average=\"micro\")\n",
    "print('Average precision score, micro-averaged over all classes: {0:0.2f}'.format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pr curve\n",
    "colors = cycle(['navy', 'turquoise', 'darkorange', 'cornflowerblue', 'teal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 8))\n",
    "f_scores = np.linspace(0.2, 0.8, num=4)\n",
    "lines = []\n",
    "labels = []\n",
    "for f_score in f_scores:\n",
    "    x = np.linspace(0.01, 1)\n",
    "    y = f_score * x / (2 * x - f_score)\n",
    "    l, = plt.plot(x[y >= 0], y[y >= 0], color='gray', alpha=0.2)\n",
    "    plt.annotate('f1={0:0.1f}'.format(f_score), xy=(0.9, y[45] + 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.append(l)\n",
    "labels.append('iso-f1 curves')\n",
    "l, = plt.plot(recall[\"micro\"], precision[\"micro\"], color='gold', lw=2)\n",
    "lines.append(l)\n",
    "labels.append('micro-average Precision-recall (area = {0:0.2f})' ''.format(average_precision[\"micro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, color in zip(range(10), colors):\n",
    "    l, = plt.plot(recall[i], precision[i], color=color, lw=2)\n",
    "    lines.append(l)\n",
    "    labels.append('Precision-recall for class {0} (area = {1:0.2f})' ''.format(i, average_precision[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "plt.legend(lines, labels, loc=(0, -1.0), prop=dict(size=14))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
